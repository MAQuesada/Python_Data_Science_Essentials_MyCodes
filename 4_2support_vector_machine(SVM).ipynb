{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Support Vector Machine(SVM)- nonLineal algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn ofrece una implementación basada en **LIBSVM** (biblioteca de implementaciones de clasificación y regresión SVM), y *LIBLINEAR* (biblioteca escalable para la clasificación lineal ideal de grandes conjuntos de datos, especialmente cualquier texto disperso). Ambas han sido escritas en C++ con una API en C para interactuar con otros lenguajes.\n",
    "\n",
    "La API en C explica bien dos necesidades complicadas para que funcionen de forma óptima bajo el\n",
    "scikit-learn de Python: \n",
    "*   LIBSVM, al funcionar, necesita reservar algo de memoria para las operaciones del **kernel**. El parámetro *cache_size* es el encargado de eso , por defecto es 200 megabytes, es aconsejable subirlo a 500 o 1000, dependiendo de los recursos disponibles\n",
    "*   Ambos esperan un ndarray de NumPy o un SciPy sparse.csr_matrix (un tipo de matriz dispersa optimizada para filas),\n",
    "preferiblemente con tipo *float64*.\n",
    "---\n",
    "Ni *LIBSVM* ni *LIBLINEAR* ofrecen una implementación capaz de manejar grandes\n",
    "conjuntos de datos. **SGDClassifier** y **SGDRegressor** son las clases de scikit-learn que\n",
    "pueden producir una solución en un tiempo computacional razonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for classification\n",
    "Posee las siguientes implementaciones: \n",
    "* `sklearn.svm.SVC`: implementacion basada en  LIBSVM  para la clasificación lineal y kernel funciona bien hasta 10 000 datos ya que tiene complejidad cubica. \n",
    "* `sklearn.svm.NuSVC`: similar que la versión .SVC\n",
    "* `sklearn.svm.OneClassSVM`: Detección no supervisada de valores atípicos\n",
    "* `sklearn.svm.LinearSVC`: Basado en LIBLINEAR es un clasificador lineal binario y multiclase\n",
    "\n",
    "Los datos q usaremos son una serie temporal de 50.000 muestras producidas por un sistema físico de un motor de combustión interna de 10 cilindros.Nuestro objetivo es binario: encendido normal del motor o fallo deencendido. \n",
    "\n",
    "Utilizaremos el conjunto de datos tal y como se ha recuperado del sitio web de *LIBSVM* utilizando el scripts *4_0download_data.ipynb*. El archivo de datos está en el formato LIBSVM y está comprimido por Bzip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1.0\n",
      "  (0, 10)\t-0.731854\n",
      "  (0, 11)\t0.173431\n",
      "  (0, 12)\t0.0\n",
      "  (0, 13)\t0.00027\n",
      "  (0, 14)\t0.011684\n",
      "  (0, 15)\t-0.011052\n",
      "  (0, 16)\t0.024452\n",
      "  (0, 17)\t0.008337\n",
      "  (0, 18)\t0.001324\n",
      "  (0, 19)\t0.025544\n",
      "  (0, 20)\t-0.040728\n",
      "  (0, 21)\t-0.00081 \n",
      " <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2500, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "X_train, y_train = load_svmlight_file('resources/ijcnn1.bz2')\n",
    "first_rows = 2500\n",
    "X_train, y_train = X_train[:first_rows,:], y_train[:first_rows]\n",
    "print(X_train[0],'\\n',type(X_train))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with rbf kernel -> cross validation accuracy: mean = 0.910 std = 0.001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "hypothesis = SVC(kernel='rbf', random_state=101)\n",
    "\n",
    "scores = cross_val_score(hypothesis, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print (\"SVC with rbf kernel -> cross validation accuracy: \\\n",
    "mean = %0.3f std = %0.3f\" % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una muestra de tamaño 15 000 obtuvimos en un timepo mucho mayor (debido a la complejidad cubuca de esta implementacion):  \n",
    ">SVC with rbf kernel -> cross validation accuracy: mean = 0.944 std = 0.018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro ejempo para probar la escalabilidad de la *SVM* en un problema multiclase y a un gran número de casos. El\n",
    "conjunto de datos Covertype, que vamos a utilizar, presenta como ejemplos un gran número de manchas de bosque de 30x30 metros en Estados  Unidos. Los datos correspondientes se recogen para la tarea de predecir la\n",
    "especie arbórea dominante de cada parche (tipo de cobertura). Se trata de\n",
    "un problema de clasificación multiclase (siete tipos de cubierta a predecir).\n",
    "Cada muestra tiene 54 características, y hay más de 580.000 ejemplos.\n",
    "\n",
    "Las clases están desequilibradas, ya que hay dos tipos de árboles con la mayoría de los ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-sample: (25000, 54)\n",
      "target freq: [('Spruce/Fir', 0.36428), ('Lodgepole Pine', 0.48488), ('Ponderosa Pine', 0.06332), ('Cottonwood/Willow', 0.0048), ('Aspen', 0.01648), ('Douglas-fir', 0.03116), ('Krummholz', 0.03508)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "covertype_dataset = pickle.load(open(\"resources/covertype_dataset.pickle\", \"rb\"))\n",
    "\n",
    "covertypes = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine',\n",
    "              'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "\n",
    "covertype_X = covertype_dataset.data[:25000, :]\n",
    "\n",
    "# restamosm uno para iniciar las class desde cero\n",
    "covertype_y = covertype_dataset.target[:25000] - 1\n",
    "\n",
    "\n",
    "print('sub-sample:', covertype_X.shape)\n",
    "print('target freq:', list(zip(covertypes, np.bincount(covertype_y)/covertype_X.shape[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que tenemos siete clases, tendremos que entrenar siete clasificadores diferentes centrados en la\n",
    "predicción de una sola clase frente a las demás (uno frente a otro es el comportamiento por defecto de **LinearSVC** en problemas multiclase). Esto es  todo un reto para muchos algoritmos, teniendo en cuenta que hay 54\n",
    "variables, pero **LinearSVC** puede demostrar cómo manejarlo en un tiempo razonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC -> cross validation accuracy: mean = 0.648 std = 0.024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "hypothesis = LinearSVC(dual=False, class_weight='balanced')\n",
    "\n",
    "# cross-validation-generator equilibrar los pliegues (es el mismo q usa por defecto cross_val_score)\n",
    "cv_strata = StratifiedKFold(n_splits=3, shuffle=True, random_state=101)\n",
    "\n",
    "scores = cross_val_score(hypothesis, covertype_X, covertype_y,\n",
    "                         cv=cv_strata, scoring='accuracy')\n",
    "print(\"LinearSVC -> cross validation accuracy: \\\n",
    "mean = %0.3f std = %0.3f\" % (np.mean(scores), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión resultante es 0.65 , que no es un mal resultado. Sin embargo, deja margen de mejora. Por otra parte, el problema parece  ser no lineal, aunque aplicar el SVM con un kernel no lineal daría lugar a un\n",
    "proceso de entrenamiento muy largo, ya que el número de observaciones\n",
    "es grande. Volveremos a plantear este problema en los siguientes ejemplos\n",
    "utilizando otros algoritmos no lineales para comprobar si podemos mejorar\n",
    "la puntuación obtenida por **LinearSVC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for regression\n",
    "Posee las siguientes implementaciones: \n",
    "* `sklearn.svm.SVR`: implementacion basada en LIBSVM para la regresión\n",
    "* `sklearn.svm.NuSVR`: Lo mismo que para .SVR \n",
    "\n",
    "Para ofrecer un ejemplo de regresión, nos decidimos por un conjunto de datos sobre los precios inmobiliarios de las viviendas en California \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "import pickle\n",
    "X_train, y_train = pickle.load(open(\"resources/cadata.pickle\", \"rb\"))\n",
    "first_rows = 2000\n",
    "\n",
    "# escalar para evitar la influencia de la diferente escala de las variables originales\n",
    "X_train = scale(X_train[:first_rows, :].toarray())\n",
    "\n",
    "# divide por1,000 para hacerla más legible en valores de mil dólares\n",
    "y_train = y_train[:first_rows]/10**4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR -> cross validation accuracy: mean = -4.652 std = 0.300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "hypothesis = SVR()\n",
    "\n",
    "# el signo negativo es sólo un truco computacional utilizado por  scikit- learn\n",
    "scores = cross_val_score(hypothesis, X_train, y_train, cv=3, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"SVR -> cross validation accuracy: mean = %0.3f \\\n",
    "std = %0.3f\" % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters SVM\n",
    "Observaciones \n",
    "1. Al igual que otros algoritmos de aprendizaje basados en combinaciones lineales, tener variables a diferentes\n",
    "escalas hace que el algoritmo se vea dominado por las características con\n",
    "mayor rango o varianza. Es aconsejable escalar todos los datos\n",
    " \n",
    "2.  El algoritmo tiende a favorecer las clases frecuentes. Una solución, aparte del\n",
    "remuestreo o del downsampling (reducir la clase mayoritaria al mismo\n",
    "número de la menos frecuente), es ponderar el *parámetro de penalización\n",
    "C* en función de la frecuencia de la clase (los valores bajos penalizarán más\n",
    "la clase, los valores altos menos). Hay dos formas de conseguirlo con\n",
    "respecto a las diferentes implementaciones; primero, está el parámetro\n",
    "*class_weight* en **SVC** (que puede establecerse con la palabra clave balanced, o\n",
    "proporcionarse con un diccionario que contenga valores específicos para\n",
    "cada clase). Luego, también está el parámetro *sample_weight* en el método\n",
    ".fit() de *SVC*,*NuSVC* ,*SVR* ,*NuSVR* , y **OneClassSVM** (requiere una matriz\n",
    "unidimensional como entrada, donde cada posición se refiere al peso decada ejemplo de entrenamiento).\n",
    "---\n",
    "* *C*: El valor de la penalización. Disminuirlo hace que el margen sea mayor, ignorando así más ruido pero también haciendo que el modelo sea más generalizable. Un valor óptimo puede considerarse normalmente en el rango de `np.logspace(-3,3, 7)`\n",
    " \n",
    "* *kernel*: se puede establecer en lineal, poly, rbf, sigmoid, o un núcleo personalizado (¡para expertos!). El más\n",
    "utilizado es sin duda *rbf*(radial basis function)\n",
    " \n",
    "* *degree*: Esto funciona con kernel='poly', señalando la dimensionalidad de la expansión polinómica. En cambio, es ignorado por otros núcleos\n",
    " \n",
    "* *gamma*: Un coeficiente para'rbf' , 'poly', y 'sigmoid'. Los valores altos tienden a ajustarse mejor a los datos, pero pueden llevar a un cierto sobreajuste. Intuitivamente, podemos imaginarnos la gamma como la influencia que un solo ejemplo ejerce sobre el modelo. Los valores bajos hacen que la influencia de cada ejemplo se sienta bastante lejos. Como\n",
    "hay que considerar muchos puntos, la curva de la SVM tenderá a tomar una forma menos influenciada por los puntos locales y el resultado será una curva de contorno mórbida. Los valores altos de gamma, en cambio, hacen que la curva tenga más en cuenta la disposición de los puntos a nivel local. Los resultados suelen estar representados por muchas burbujas pequeñas que explican la influencia ejercida por los puntos locales. El rango de búsqueda sugerido para este hiperparámetro es `np.logspace(-3, 3, 7)`\n",
    " \n",
    "* *nu* : Para la regresión y la clasificación con **NuSVR** y *NuSVC*, este parámetro aproxima los puntos de\n",
    "entrenamiento que no se clasifican con confianza, es decir, los puntos mal clasificados y los puntos correctos dentro o en el margen. Debe estar en el rango de [0,1], ya que es una proporción relativa a su conjunto de entrenamiento. Al final, actúa como C, con proporciones altas que amplían el margen\n",
    " \n",
    "* *epsilon*: Este parámetro especifica cuánto error va a aceptar el SVR  definiendo un rango grande epsilon donde no se asocia ninguna penalización con respecto al valor verdadero del punto. El rango de búsqueda sugerido es\n",
    "`np.insert(np.logspace(-4, 2, 7),0,[0])`. \n",
    " \n",
    "* *penalty*, *loss*, and *dual*: For LinearSVC, these parameters accept the ('l1','squared_hinge',False), ('l2','hinge',True),\n",
    "('l2','squared_hinge',True), and ('l2','squared_hinge',False)combinations.\n",
    " The ('l2','hinge',True) combination is analogous to the SVC (kernel='linear'). \n",
    "\n",
    "* El problema *dual* es más fácil de resolver cuando el numero de instancias de entrenamiento es menor que el número de caracteristicas  y ademas permite realizar el **Trick kernel** mientras que el primario no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'gamma': 0.1, 'C': 100}\n",
      "Cross validation accuracy: mean = 0.997\n"
     ]
    }
   ],
   "source": [
    "# Intentaremos mejorar la precisión inicial de 0,91 en el conjunto de datos IJCNN'01 buscando\n",
    "# mejores valores de grado,C , y gamma.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X_train, y_train = load_svmlight_file('resources/ijcnn1.bz2')\n",
    "first_rows = 5000\n",
    "X_train, y_train = X_train[:first_rows, :], y_train[:first_rows]\n",
    "\n",
    "hypothesis = SVC(kernel='rbf', random_state=101)\n",
    "\n",
    "search_dict = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "search_func = RandomizedSearchCV(estimator=hypothesis,\n",
    "                                 param_distributions=search_dict,\n",
    "                                 n_iter=10, scoring='accuracy',\n",
    "                                 n_jobs=-1, refit=True,\n",
    "                                 cv=5, random_state=101)\n",
    "search_func.fit(X_train, y_train)\n",
    "print('Best parameters %s' % search_func.best_params_)\n",
    "print('Cross validation accuracy: mean = %0.3f' %\n",
    "      search_func.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37964de45fa06bc99b754cfc54b483ffac9c133df6b16baa187ef33bd89a6318"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
